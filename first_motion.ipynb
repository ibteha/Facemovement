{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/ibteha/Facemovement.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14199,
     "status": "ok",
     "timestamp": 1618554723185,
     "user": {
      "displayName": "Ahmad Ibtehaj",
      "photoUrl": "",
      "userId": "12881388615122616120"
     },
     "user_tz": -300
    },
    "id": "ReCLWlcih9Uw",
    "outputId": "1fdb66ad-be63-45f1-d544-9a2048430d2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cffi==1.11.5 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.11.5)\n",
      "Requirement already satisfied: cloudpickle==0.5.3 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.5.3)\n",
      "Requirement already satisfied: cycler==0.10.0 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (0.10.0)\n",
      "Requirement already satisfied: dask==0.18.2 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.18.2)\n",
      "Requirement already satisfied: decorator==4.3.0 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (4.3.0)\n",
      "Requirement already satisfied: imageio==2.3.0 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: kiwisolver==1.0.1 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (1.0.1)\n",
      "Requirement already satisfied: matplotlib==2.2.2 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (2.2.2)\n",
      "Requirement already satisfied: networkx==2.1 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 9)) (2.1)\n",
      "Requirement already satisfied: numpy==1.15.0 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 10)) (1.15.0)\n",
      "Requirement already satisfied: pandas==0.23.4 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 11)) (0.23.4)\n",
      "Requirement already satisfied: Pillow==5.2.0 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 12)) (5.2.0)\n",
      "Requirement already satisfied: pycparser==2.18 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 13)) (2.18)\n",
      "Requirement already satisfied: pygit==0.1 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 14)) (0.1)\n",
      "Requirement already satisfied: pyparsing==2.2.0 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 15)) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil==2.7.3 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 16)) (2.7.3)\n",
      "Requirement already satisfied: pytz==2018.5 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 17)) (2018.5)\n",
      "Requirement already satisfied: PyWavelets==0.5.2 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 18)) (0.5.2)\n",
      "Requirement already satisfied: PyYAML==5.1 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 19)) (5.1)\n",
      "Requirement already satisfied: scikit-image==0.14.0 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 20)) (0.14.0)\n",
      "Requirement already satisfied: scikit-learn==0.19.2 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 21)) (0.19.2)\n",
      "Requirement already satisfied: scipy==1.1.0 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 22)) (1.1.0)\n",
      "Requirement already satisfied: six==1.11.0 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 23)) (1.11.0)\n",
      "Requirement already satisfied: toolz==0.9.0 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 24)) (0.9.0)\n",
      "Requirement already satisfied: torch==1.0.0 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 25)) (1.0.0)\n",
      "Requirement already satisfied: torchvision==0.2.1 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 26)) (0.2.1)\n",
      "Requirement already satisfied: tqdm==4.24.0 in ./env/lib/python3.6/site-packages (from -r requirements.txt (line 27)) (4.24.0)\n",
      "Requirement already satisfied: setuptools in ./env/lib/python3.6/site-packages (from kiwisolver==1.0.1->-r requirements.txt (line 7)) (58.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ibtehaj/Documents/ibtehaj/first-order-motion/env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in ./env/lib/python3.6/site-packages (4.5.4.58)\n",
      "Requirement already satisfied: numpy>=1.13.3 in ./env/lib/python3.6/site-packages (from opencv-python) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ibtehaj/Documents/ibtehaj/first-order-motion/env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30608,
     "status": "ok",
     "timestamp": 1618565374355,
     "user": {
      "displayName": "Ahmad Ibtehaj",
      "photoUrl": "",
      "userId": "12881388615122616120"
     },
     "user_tz": -300
    },
    "id": "pM6ldi9LSrJT",
    "outputId": "6c33449e-a7f2-4117-ab1e-c6b0fd32bc2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.14.2\n",
      "  Downloading numpy-1.14.2-cp36-cp36m-manylinux1_x86_64.whl (12.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.2 MB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.15.0\n",
      "    Uninstalling numpy-1.15.0:\n",
      "      Successfully uninstalled numpy-1.15.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "numba 0.53.1 requires numpy>=1.15, but you have numpy 1.14.2 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.14.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ibtehaj/Documents/ibtehaj/first-order-motion/env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-cache-dir numpy==1.14.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "executionInfo": {
     "elapsed": 18600,
     "status": "error",
     "timestamp": 1618554766093,
     "user": {
      "displayName": "Ahmad Ibtehaj",
      "photoUrl": "",
      "userId": "12881388615122616120"
     },
     "user_tz": -300
    },
    "id": "AC43845DC1ef",
    "outputId": "c8d7cb4b-7ef3-4aa7-91a9-d42e3cafa98a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of faces Detected:0\n"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "#from imutils import face_utils\n",
    "import numpy as np\n",
    "#from PIL import Image\n",
    "\n",
    "def rectangle(rect):\n",
    "    # take a bounding predicted by dlib and convert it\n",
    "    # to the format (x, y, w, h) as we would normally do\n",
    "    # with OpenCV\n",
    "    x = rect.left()\n",
    "    y = rect.top()\n",
    "    w = rect.right() - x\n",
    "    h = rect.bottom() - y\n",
    "    \n",
    "    # return a tuple of (x, y, w, h) (x,y)->Top-left corner w->width of rect h->depth of rect\n",
    "    return (x, y, w, h)\n",
    "\n",
    "\n",
    "\n",
    "load = \"/home/ibtehaj/Documents/ibtehaj/first-order-motion/1.png\"\n",
    "image = cv2.imread(load)\n",
    "\n",
    "#convert from RBG to grayscale i.e.,PRE-PROCESS\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# dlib frontal face detector is used to find the faces\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "#to predict the 68 landmark features on the face- from which we use first 17(jaw line) landmarks\n",
    "predictor_path = \"/home/ibtehaj/Documents/ibtehaj/first-order-motion/alignment/face-alignment-dlib/shape_predictor_68_face_landmarks.dat\"\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "# detect faces in the grayscale image\n",
    "face_rects = detector(gray, 1) \n",
    "\n",
    "#prints Number of detected faces\n",
    "print(\"\\nNumber of faces Detected:\"+str(len(face_rects)))\n",
    "\n",
    "# loop over the face detections\n",
    "for (i, rect) in enumerate(face_rects):\n",
    "    \n",
    "    #returned values are stored in tuple top-left  corner and width and height\n",
    "    (x1, y1, w, h) = rectangle(rect)\n",
    "    \n",
    "    #make a new black image on which we stick our cropped face this is of input image dimensions \n",
    "    out_face = np.zeros_like(image)\n",
    "    \n",
    "    \n",
    "    #prints each detected face top-left corners and width and height\n",
    "    print(\"Face:\"+str(i+1))\n",
    "    \n",
    "    #landmark predictor given a image and a face\n",
    "    shape = predictor(gray, rect)\n",
    "    \n",
    "    #finding the landmark points and manually give top two edges\n",
    "    pts = np.empty([18, 2], dtype = int)\n",
    "    for j in range(18):\n",
    "        if j == 0:\n",
    "            pts[j][0] = x1\n",
    "            pts[j][1] = y1\n",
    "        elif j == 17:\n",
    "            pts[j][0] = x1+w\n",
    "            pts[j][1] = y1\n",
    "        else:\n",
    "            pts[j][0] = shape.part(j).x\n",
    "            pts[j][1] = shape.part(j).y\n",
    "    \n",
    "    #constructing a mask\n",
    "    remapped_shape =  np.zeros_like(shape)\n",
    "    image_mask = np.zeros((image.shape[0],image.shape[1]))\n",
    "    \n",
    "    #array of landmark pts\n",
    "    print('Facial Landmarks:')\n",
    "    print(pts)\n",
    "    \n",
    "    #marking the crop region in mask\n",
    "    cv2.fillPoly(image_mask,[np.array(pts, dtype=np.int32)],1)\n",
    "    image_mask = image_mask.astype(np.bool)\n",
    "    \n",
    "    #inserting that mask on output image\n",
    "    out_face[image_mask] = image[image_mask]\n",
    "    \n",
    "    #splitting the channels\n",
    "    b_channel, g_channel, r_channel = cv2.split(out_face)\n",
    "    \n",
    "    #initializing alpha channel\n",
    "    alpha_channel = np.zeros_like(gray)\n",
    "    \n",
    "    #assigning opaque value at image existing pixels\n",
    "    for p in range(alpha_channel.shape[0]):\n",
    "        for q in range(alpha_channel.shape[1]):\n",
    "            if b_channel[p][q]!=0 or g_channel[p][q]!=0 or r_channel[p][q]!=0:\n",
    "                alpha_channel[p][q] = 255\n",
    "                \n",
    "    #merging the four channels\n",
    "    output_face = cv2.merge((b_channel, g_channel, r_channel, alpha_channel))\n",
    "    \n",
    "    #outputting the dark background face cropped image \n",
    "    string = \"output\"+str(i+1)+\".png\"\n",
    "    cv2.imwrite(string, output_face)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 1903,
     "status": "ok",
     "timestamp": 1618548458714,
     "user": {
      "displayName": "Ahmad Ibtehaj",
      "photoUrl": "",
      "userId": "12881388615122616120"
     },
     "user_tz": -300
    },
    "id": "Fo3EX6QQy4ho",
    "outputId": "6462a76d-06da-47a7-8357-d02fee6b134e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.15.0\n",
      "  Using cached numpy-1.15.0-cp36-cp36m-manylinux1_x86_64.whl (13.9 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "Successfully installed numpy-1.15.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ibtehaj/Documents/ibtehaj/first-order-motion/env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.1.0\n",
      "  Downloading torch-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (676.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 676.9 MB 9.8 kB/s eta 0:00:01    |███▋                            | 76.0 MB 781 kB/s eta 0:12:50     |█████████████████▍              | 367.6 MB 2.3 MB/s eta 0:02:12     |████████████████████████▋       | 520.4 MB 2.0 MB/s eta 0:01:19     |████████████████████████████▍   | 601.4 MB 44 kB/s eta 0:28:12     |███████████████████████████████ | 655.9 MB 2.6 MB/s eta 0:00:09     |███████████████████████████████▌| 666.1 MB 2.5 MB/s eta 0:00:05\n",
      "\u001b[?25hCollecting torchvision==0.3.0\n",
      "  Downloading torchvision-0.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./env/lib/python3.6/site-packages (from torch==1.1.0) (1.15.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in ./env/lib/python3.6/site-packages (from torchvision==0.3.0) (8.4.0)\n",
      "Requirement already satisfied: six in ./env/lib/python3.6/site-packages (from torchvision==0.3.0) (1.11.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 0.4.1\n",
      "    Uninstalling torch-0.4.1:\n",
      "      Successfully uninstalled torch-0.4.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.2.1\n",
      "    Uninstalling torchvision-0.2.1:\n",
      "      Successfully uninstalled torchvision-0.2.1\n",
      "Successfully installed torch-1.1.0 torchvision-0.3.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ibtehaj/Documents/ibtehaj/first-order-motion/env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.1.0 torchvision==0.3.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1512,
     "status": "ok",
     "timestamp": 1618548453388,
     "user": {
      "displayName": "Ahmad Ibtehaj",
      "photoUrl": "",
      "userId": "12881388615122616120"
     },
     "user_tz": -300
    },
    "id": "JV4SM-6_50Yk",
    "outputId": "5f61ac2b-4180-4a89-a491-d338d9489462"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:Warning: the frame size for reading (1080, 1920) is different from the source frame size (1920, 1080).\n",
      "417it [05:06,  1.36it/s]\n",
      "1\n",
      "ffmpeg -i /home/ibtehaj/Documents/ibtehaj/first-order-motion/32.mp4 -ss 0.0 -t 13.866666666666667 -filter:v \"crop=1080:1281:0:406, scale=256:256\" ./cropped-output/32/crop1635830317.90367.mp4\n",
      "sh: 1: ffmpeg: not found\n"
     ]
    }
   ],
   "source": [
    "!python crop-video1.py --inp '/home/ibtehaj/Documents/ibtehaj/first-order-motion/video_input/32.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1176,
     "status": "ok",
     "timestamp": 1618565405237,
     "user": {
      "displayName": "Ahmad Ibtehaj",
      "photoUrl": "",
      "userId": "12881388615122616120"
     },
     "user_tz": -300
    },
    "id": "KTtn0N5PiI-8",
    "outputId": "d9cfce8e-1822-43d9-ac7a-a1315a8626ca"
   },
   "outputs": [],
   "source": [
    "cd /content/drive/My Drive/Ibtehaj/FSGAN/First_order_motion/implemented/first-order-motion/first-order-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3258,
     "status": "ok",
     "timestamp": 1618565411349,
     "user": {
      "displayName": "Ahmad Ibtehaj",
      "photoUrl": "",
      "userId": "12881388615122616120"
     },
     "user_tz": -300
    },
    "id": "sI78-As5iDY4",
    "outputId": "7347b573-0feb-40fc-d693-c438c6d021ee"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "from tqdm import tqdm\n",
    "video = imageio.get_reader(\"/home/ibtehaj/Documents/ibtehaj/first-order-motion/1.mp4\")\n",
    "fps = video.get_meta_data()['fps']\n",
    "try :\n",
    "    for i, frame in tqdm(enumerate(video)):\n",
    "        pass\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2142,
     "status": "ok",
     "timestamp": 1618565411351,
     "user": {
      "displayName": "Ahmad Ibtehaj",
      "photoUrl": "",
      "userId": "12881388615122616120"
     },
     "user_tz": -300
    },
    "id": "tI2LsHSJikEg",
    "outputId": "ad66add2-d5ab-4812-8e61-5a59b4aa4d67"
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "cap = cv2.VideoCapture(\"/home/ibtehaj/Documents/ibtehaj/first-order-motion/321.mp4\")\n",
    "i=0\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print( length )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "executionInfo": {
     "elapsed": 2525,
     "status": "ok",
     "timestamp": 1618565414567,
     "user": {
      "displayName": "Ahmad Ibtehaj",
      "photoUrl": "",
      "userId": "12881388615122616120"
     },
     "user_tz": -300
    },
    "id": "QCQMVnSfnYEx",
    "outputId": "32f318af-63ba-4472-db1c-3a0fb2ae3906"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Loading the image to be tested\n",
    "test_image = cv2.imread(\"/home/ibtehaj/Documents/ibtehaj/first-order-motion/1.png\")\n",
    "\n",
    "#Converting to grayscale\n",
    "test_image_gray = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Displaying the grayscale image\n",
    "plt.imshow(test_image_gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9oNFTv18oQSW"
   },
   "outputs": [],
   "source": [
    "def convertToRGB(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdGLg42mGqyd"
   },
   "outputs": [],
   "source": [
    " haar_cascade_face = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1269,
     "status": "ok",
     "timestamp": 1618565420916,
     "user": {
      "displayName": "Ahmad Ibtehaj",
      "photoUrl": "",
      "userId": "12881388615122616120"
     },
     "user_tz": -300
    },
    "id": "1Ffat6HFnj5X",
    "outputId": "ffab521d-2095-454b-f56f-ca406e1f22e2"
   },
   "outputs": [],
   "source": [
    "haar_cascade_face = cv2.CascadeClassifier(\"/home/ibtehaj/Documents/ibtehaj/first-order-motion/first-order-model/haarcascade_frontalface_default.xml\")\n",
    "faces_rects = haar_cascade_face.detectMultiScale(test_image, scaleFactor = 1.2, minNeighbors = 5);\n",
    "\n",
    "# Let us print the no. of faces found\n",
    "print('Faces found: ', len(faces_rects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1535,
     "status": "ok",
     "timestamp": 1618565423845,
     "user": {
      "displayName": "Ahmad Ibtehaj",
      "photoUrl": "",
      "userId": "12881388615122616120"
     },
     "user_tz": -300
    },
    "id": "GM8pznUKm2Q_",
    "outputId": "3eb4cd41-575e-48d8-e90e-69aa6d365e69"
   },
   "outputs": [],
   "source": [
    "faces_rects = haar_cascade_face.detectMultiScale(test_image_gray, scaleFactor = 1.2, minNeighbors = 5);\n",
    "\n",
    "# Let us print the no. of faces found\n",
    "print('Faces found: ', len(faces_rects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01JcZwLsvB7b"
   },
   "outputs": [],
   "source": [
    "for (x,y,w,h) in faces_rects:\n",
    "     cv2.rectangle(test_image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skvideo\n",
    "skvideo.setFFmpegPath(\"C:\\\\ffmpeg\") # you need this before the import\n",
    "import skvideo.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_video =\"/home/ibtehaj/Documents/ibtehaj/first-order-motion/1.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imageio==2.3.0 scikit-image==0.14.0 scikit-learn==0.19.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ascertaining binaries for: ffmpeg.\r\n"
     ]
    }
   ],
   "source": [
    "# !imageio_download_bin ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 741
    },
    "executionInfo": {
     "elapsed": 19450,
     "status": "ok",
     "timestamp": 1618565496407,
     "user": {
      "displayName": "Ahmad Ibtehaj",
      "photoUrl": "",
      "userId": "12881388615122616120"
     },
     "user_tz": -300
    },
    "id": "9EJ2QcfSO6pZ",
    "outputId": "c5823bf2-f852-4f6c-8b62-d5e42342adf1"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from skimage.transform import resize\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import skvideo.io  \n",
    "\n",
    "# driving_video =skvideo.io.vread(\"/home/ibtehaj/Documents/ibtehaj/first-order-motion/1.mp4\")\n",
    "\n",
    "source_image = imageio.imread(\"/home/ibtehaj/Documents/ibtehaj/first-order-motion/input_image/96.png\")\n",
    "# driving_video = imageio.mimread('./video_input/test4.mp4')\n",
    "driving_video = imageio.get_reader(\"/home/ibtehaj/Documents/ibtehaj/first-order-motion/cropped-output/22.mp4\")\n",
    "\n",
    "\n",
    "#Resize image and video to 256x256\n",
    "\n",
    "source_image = resize(source_image, (256,256))[..., :3]\n",
    "driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
    "\n",
    "def display(source, driving, generated=None):\n",
    "    fig = plt.figure(figsize=(12 + 4 * (generated is not None), 10))\n",
    "\n",
    "    ims = []\n",
    "    for i in range(len(driving)):\n",
    "        cols = [source]\n",
    "        cols.append(driving[i])\n",
    "        if generated is not None:\n",
    "            cols.append(generated[i])\n",
    "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
    "        plt.axis('off')\n",
    "        ims.append([im])\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n",
    "    plt.close()\n",
    "    return ani\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "AKWi2L1UO-mW"
   },
   "outputs": [],
   "source": [
    "from demo import load_checkpoints\n",
    "generator, kp_detector = load_checkpoints(config_path='/home/ibtehaj/Documents/ibtehaj/first-order-motion/config/vox-256.yaml', \n",
    "                            checkpoint_path='/home/ibtehaj/Documents/ibtehaj/first-order-motion/checkpoints/vox-cpk.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 758
    },
    "executionInfo": {
     "elapsed": 34133,
     "status": "ok",
     "timestamp": 1618565518501,
     "user": {
      "displayName": "Ahmad Ibtehaj",
      "photoUrl": "",
      "userId": "12881388615122616120"
     },
     "user_tz": -300
    },
    "id": "njEulpluPG9I",
    "outputId": "c2efaf5c-4037-45cd-ec4b-fd6132cc98f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:04<00:00, 33.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from demo import make_animation\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True)\n",
    "#save resulting video\n",
    "imageio.mimsave('./output/result/96.mp4', [img_as_ubyte(frame) for frame in predictions])\n",
    "#video can be downloaded from /content folder\n",
    "\n",
    "# HTML(display(source_image, driving_video, predictions).to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKHOOlyCl7BQ"
   },
   "outputs": [],
   "source": [
    "ffmpeg -i \"./output/generated_anime_122.mp4\" -vf fps=1 /out%d.png"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "first_motion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
